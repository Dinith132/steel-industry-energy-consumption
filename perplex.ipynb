{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Data Preparation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset (replace with your data path)\n",
    "url = \"Steel_industry_data.csv\"\n",
    "df = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Usage_kWh</th>\n",
       "      <th>Lagging_Current_Reactive.Power_kVarh</th>\n",
       "      <th>Leading_Current_Reactive_Power_kVarh</th>\n",
       "      <th>CO2(tCO2)</th>\n",
       "      <th>Lagging_Current_Power_Factor</th>\n",
       "      <th>Leading_Current_Power_Factor</th>\n",
       "      <th>NSM</th>\n",
       "      <th>WeekStatus</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Load_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2018 00:15</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.21</td>\n",
       "      <td>100.0</td>\n",
       "      <td>900</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2018 00:30</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.77</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1800</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2018 00:45</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.28</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2700</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2018 01:00</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.09</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3600</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2018 01:15</td>\n",
       "      <td>3.82</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.72</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4500</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  Usage_kWh  Lagging_Current_Reactive.Power_kVarh  \\\n",
       "0  01/01/2018 00:15       3.17                                  2.95   \n",
       "1  01/01/2018 00:30       4.00                                  4.46   \n",
       "2  01/01/2018 00:45       3.24                                  3.28   \n",
       "3  01/01/2018 01:00       3.31                                  3.56   \n",
       "4  01/01/2018 01:15       3.82                                  4.50   \n",
       "\n",
       "   Leading_Current_Reactive_Power_kVarh  CO2(tCO2)  \\\n",
       "0                                   0.0        0.0   \n",
       "1                                   0.0        0.0   \n",
       "2                                   0.0        0.0   \n",
       "3                                   0.0        0.0   \n",
       "4                                   0.0        0.0   \n",
       "\n",
       "   Lagging_Current_Power_Factor  Leading_Current_Power_Factor   NSM  \\\n",
       "0                         73.21                         100.0   900   \n",
       "1                         66.77                         100.0  1800   \n",
       "2                         70.28                         100.0  2700   \n",
       "3                         68.09                         100.0  3600   \n",
       "4                         64.72                         100.0  4500   \n",
       "\n",
       "  WeekStatus Day_of_week   Load_Type  \n",
       "0    Weekday      Monday  Light_Load  \n",
       "1    Weekday      Monday  Light_Load  \n",
       "2    Weekday      Monday  Light_Load  \n",
       "3    Weekday      Monday  Light_Load  \n",
       "4    Weekday      Monday  Light_Load  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables\n",
    "encoder = OrdinalEncoder()\n",
    "df[['WeekStatus', 'Load_Type']] = encoder.fit_transform(df[['WeekStatus', 'Load_Type']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Usage_kWh</th>\n",
       "      <th>Lagging_Current_Reactive.Power_kVarh</th>\n",
       "      <th>Leading_Current_Reactive_Power_kVarh</th>\n",
       "      <th>CO2(tCO2)</th>\n",
       "      <th>Lagging_Current_Power_Factor</th>\n",
       "      <th>Leading_Current_Power_Factor</th>\n",
       "      <th>NSM</th>\n",
       "      <th>WeekStatus</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Load_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2018 00:15</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.21</td>\n",
       "      <td>100.0</td>\n",
       "      <td>900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2018 00:30</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.77</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2018 00:45</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.28</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2018 01:00</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.09</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2018 01:15</td>\n",
       "      <td>3.82</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.72</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  Usage_kWh  Lagging_Current_Reactive.Power_kVarh  \\\n",
       "0  01/01/2018 00:15       3.17                                  2.95   \n",
       "1  01/01/2018 00:30       4.00                                  4.46   \n",
       "2  01/01/2018 00:45       3.24                                  3.28   \n",
       "3  01/01/2018 01:00       3.31                                  3.56   \n",
       "4  01/01/2018 01:15       3.82                                  4.50   \n",
       "\n",
       "   Leading_Current_Reactive_Power_kVarh  CO2(tCO2)  \\\n",
       "0                                   0.0        0.0   \n",
       "1                                   0.0        0.0   \n",
       "2                                   0.0        0.0   \n",
       "3                                   0.0        0.0   \n",
       "4                                   0.0        0.0   \n",
       "\n",
       "   Lagging_Current_Power_Factor  Leading_Current_Power_Factor   NSM  \\\n",
       "0                         73.21                         100.0   900   \n",
       "1                         66.77                         100.0  1800   \n",
       "2                         70.28                         100.0  2700   \n",
       "3                         68.09                         100.0  3600   \n",
       "4                         64.72                         100.0  4500   \n",
       "\n",
       "   WeekStatus Day_of_week  Load_Type  \n",
       "0         0.0      Monday        0.0  \n",
       "1         0.0      Monday        0.0  \n",
       "2         0.0      Monday        0.0  \n",
       "3         0.0      Monday        0.0  \n",
       "4         0.0      Monday        0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dinit\\AppData\\Local\\Temp\\ipykernel_956\\3086138976.py:1: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('H', on='date').agg({\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = df.resample('H', on='date').agg({\n",
    "    'Usage_kWh': 'mean',\n",
    "    'Lagging_Current_Reactive.Power_kVarh': 'mean',  # Corrected column name\n",
    "    'Leading_Current_Reactive_Power_kVarh': 'mean',\n",
    "    'CO2(tCO2)': 'mean',\n",
    "    'Lagging_Current_Power_Factor': 'mean',\n",
    "    'Leading_Current_Power_Factor': 'mean',\n",
    "    'NSM': 'first',\n",
    "    'WeekStatus': 'first',\n",
    "    'Load_Type': 'first'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sliding window transformation\n",
    "def create_sliding_windows(data, window_size=3):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)-window_size):\n",
    "        X.append(data[i:i+window_size])\n",
    "        y.append(data[i+window_size, 0])  # First column is target (Usage_kWh)\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 16  # Best from paper\n",
    "X, y = create_sliding_windows(scaled_data, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (82-18)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.18, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Model Architecture\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(model_type='single', input_shape=(16, 9)):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if model_type == 'single':\n",
    "        model.add(LSTM(64, input_shape=input_shape))\n",
    "    elif model_type == 'double':\n",
    "        model.add(LSTM(64, return_sequences=True, input_shape=input_shape))\n",
    "        model.add(LSTM(64))\n",
    "    elif model_type == 'bidirectional':\n",
    "        model.add(Bidirectional(LSTM(64), input_shape=input_shape))\n",
    "    \n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dinit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize best model (double-layer)\n",
    "model = build_lstm_model('double', (window_size, X_train.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 3. Model Training\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - loss: 0.0359 - mae: 0.1458 - val_loss: 0.0198 - val_mae: 0.0999\n",
      "Epoch 2/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0227 - mae: 0.1100 - val_loss: 0.0157 - val_mae: 0.0863\n",
      "Epoch 3/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.0208 - mae: 0.1007 - val_loss: 0.0149 - val_mae: 0.0841\n",
      "Epoch 4/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0167 - mae: 0.0889 - val_loss: 0.0119 - val_mae: 0.0763\n",
      "Epoch 5/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0131 - mae: 0.0799 - val_loss: 0.0085 - val_mae: 0.0613\n",
      "Epoch 6/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0108 - mae: 0.0696 - val_loss: 0.0079 - val_mae: 0.0562\n",
      "Epoch 7/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 0.0098 - mae: 0.0652 - val_loss: 0.0074 - val_mae: 0.0542\n",
      "Epoch 8/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.0097 - mae: 0.0647 - val_loss: 0.0069 - val_mae: 0.0503\n",
      "Epoch 9/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0093 - mae: 0.0624 - val_loss: 0.0090 - val_mae: 0.0621\n",
      "Epoch 10/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 0.0096 - mae: 0.0628 - val_loss: 0.0068 - val_mae: 0.0502\n",
      "Epoch 11/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.0087 - mae: 0.0594 - val_loss: 0.0067 - val_mae: 0.0533\n",
      "Epoch 12/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 0.0089 - mae: 0.0614 - val_loss: 0.0070 - val_mae: 0.0525\n",
      "Epoch 13/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - loss: 0.0090 - mae: 0.0594 - val_loss: 0.0065 - val_mae: 0.0496\n",
      "Epoch 14/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 0.0079 - mae: 0.0556 - val_loss: 0.0061 - val_mae: 0.0480\n",
      "Epoch 15/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.0078 - mae: 0.0562 - val_loss: 0.0061 - val_mae: 0.0472\n",
      "Epoch 16/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 0.0078 - mae: 0.0561 - val_loss: 0.0059 - val_mae: 0.0481\n",
      "Epoch 17/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 0.0078 - mae: 0.0567 - val_loss: 0.0057 - val_mae: 0.0437\n",
      "Epoch 18/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 0.0071 - mae: 0.0519 - val_loss: 0.0056 - val_mae: 0.0459\n",
      "Epoch 19/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.0075 - mae: 0.0541 - val_loss: 0.0059 - val_mae: 0.0460\n",
      "Epoch 20/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 0.0069 - mae: 0.0512 - val_loss: 0.0054 - val_mae: 0.0424\n",
      "Epoch 21/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0069 - mae: 0.0519 - val_loss: 0.0055 - val_mae: 0.0433\n",
      "Epoch 22/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0062 - mae: 0.0482 - val_loss: 0.0053 - val_mae: 0.0429\n",
      "Epoch 23/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 0.0062 - mae: 0.0479 - val_loss: 0.0054 - val_mae: 0.0439\n",
      "Epoch 24/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 0.0063 - mae: 0.0492 - val_loss: 0.0051 - val_mae: 0.0418\n",
      "Epoch 25/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - loss: 0.0067 - mae: 0.0507 - val_loss: 0.0049 - val_mae: 0.0403\n",
      "Epoch 26/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 0.0064 - mae: 0.0490 - val_loss: 0.0050 - val_mae: 0.0422\n",
      "Epoch 27/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 0.0062 - mae: 0.0485 - val_loss: 0.0054 - val_mae: 0.0435\n",
      "Epoch 28/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 0.0059 - mae: 0.0471 - val_loss: 0.0049 - val_mae: 0.0411\n",
      "Epoch 29/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 0.0061 - mae: 0.0479 - val_loss: 0.0055 - val_mae: 0.0442\n",
      "Epoch 30/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 0.0057 - mae: 0.0456 - val_loss: 0.0052 - val_mae: 0.0415\n",
      "Epoch 31/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.0054 - mae: 0.0445 - val_loss: 0.0050 - val_mae: 0.0415\n",
      "Epoch 32/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.0059 - mae: 0.0462 - val_loss: 0.0050 - val_mae: 0.0396\n",
      "Epoch 33/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 0.0059 - mae: 0.0466 - val_loss: 0.0051 - val_mae: 0.0409\n",
      "Epoch 34/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.0057 - mae: 0.0454 - val_loss: 0.0048 - val_mae: 0.0387\n",
      "Epoch 35/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 0.0055 - mae: 0.0443 - val_loss: 0.0050 - val_mae: 0.0400\n",
      "Epoch 36/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 0.0054 - mae: 0.0438 - val_loss: 0.0051 - val_mae: 0.0411\n",
      "Epoch 37/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 0.0057 - mae: 0.0455 - val_loss: 0.0049 - val_mae: 0.0400\n",
      "Epoch 38/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.0056 - mae: 0.0451 - val_loss: 0.0048 - val_mae: 0.0389\n",
      "Epoch 39/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0052 - mae: 0.0432 - val_loss: 0.0058 - val_mae: 0.0460\n",
      "Epoch 40/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.0053 - mae: 0.0444 - val_loss: 0.0048 - val_mae: 0.0382\n",
      "Epoch 41/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0054 - mae: 0.0442 - val_loss: 0.0050 - val_mae: 0.0404\n",
      "Epoch 42/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0053 - mae: 0.0443 - val_loss: 0.0047 - val_mae: 0.0375\n",
      "Epoch 43/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0052 - mae: 0.0433 - val_loss: 0.0049 - val_mae: 0.0381\n",
      "Epoch 44/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 0.0051 - mae: 0.0423 - val_loss: 0.0049 - val_mae: 0.0391\n",
      "Epoch 45/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0054 - mae: 0.0442 - val_loss: 0.0049 - val_mae: 0.0402\n",
      "Epoch 46/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0053 - mae: 0.0438 - val_loss: 0.0049 - val_mae: 0.0397\n",
      "Epoch 47/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 0.0051 - mae: 0.0421 - val_loss: 0.0049 - val_mae: 0.0387\n",
      "Epoch 48/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0053 - mae: 0.0435 - val_loss: 0.0046 - val_mae: 0.0361\n",
      "Epoch 49/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.0048 - mae: 0.0413 - val_loss: 0.0050 - val_mae: 0.0398\n",
      "Epoch 50/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.0050 - mae: 0.0417 - val_loss: 0.0048 - val_mae: 0.0370\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4. Evaluation Metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def willmott_index(y_true, y_pred):\n",
    "    numerator = np.sum((y_pred - y_true)**2)\n",
    "    denominator = np.sum((np.abs(y_pred - np.mean(y_true)) + \n",
    "                        np.abs(y_true - np.mean(y_true)))**2)\n",
    "    return 1 - (numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "\tfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\t# Predict on test data\n",
    "\ty_pred = model.predict(X_test)\n",
    "\n",
    "\t# Calculate metrics\n",
    "\tmse = mean_squared_error(y_test, y_pred)\n",
    "\tmae = mean_absolute_error(y_test, y_pred)\n",
    "\tr2 = r2_score(y_test, y_pred)\n",
    "\n",
    "\treturn {\"MSE\": mse, \"MAE\": mae, \"R2\": r2}\n",
    "metrics = evaluate_model(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.00567912537267371,\n",
       " 'MAE': 0.043865385186735446,\n",
       " 'R2': 0.8810534898720461}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5. XAI with SHAP\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample background data for SHAP\n",
    "background = X_train[np.random.choice(X_train.shape[0], 100, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tf_keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 1. Install required package\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Run in terminal: pip install tf_keras\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 2. Import from standalone tf_keras\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m set_session\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 3. Configure session\u001b[39;00m\n\u001b[0;32m     11\u001b[0m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mdisable_eager_execution()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import shap\n",
    "\n",
    "# 1. Install required package\n",
    "# Run in terminal: pip install tf_keras\n",
    "\n",
    "# 2. Import from standalone tf_keras\n",
    "from tf_keras.backend import set_session\n",
    "\n",
    "# 3. Configure session\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "set_session(session)\n",
    "\n",
    "# 4. SHAP implementation\n",
    "explainer = shap.DeepExplainer(model, background, session=session)\n",
    "shap_values = explainer.shap_values(X_test[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot feature importance\n",
    "shap.summary_plot(shap_values, X_test[:100], feature_names=df.columns)\n",
    "\n",
    "### 6. Prediction Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Inverse transform predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_test_inv = scaler.inverse_transform(np.concatenate((\n",
    "    y_test.reshape(-1,1), \n",
    "    np.zeros((len(y_test), scaled_data.shape[1]-1))\n",
    "), axis=1))[:,0]\n",
    "\n",
    "y_pred_inv = scaler.inverse_transform(np.concatenate((\n",
    "    y_pred.reshape(-1,1), \n",
    "    np.zeros((len(y_pred), scaled_data.shape[1]-1))\n",
    "), axis=1))[:,0]\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(y_test_inv, label='Actual')\n",
    "plt.plot(y_pred_inv, label='Predicted', alpha=0.7)\n",
    "plt.title('Energy Consumption Forecasting')\n",
    "plt.ylabel('kWh')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "### 7. Model Saving\n",
    "model.save('energy_forecast_lstm.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
